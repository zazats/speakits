<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv=”Permissions-Policy” content=”interest-cohort=()”>
    <title>S P E A K I T X</title>
    <script src="speakits_viewer_files/three.min.js"></script>
    <script src="speakits_viewer_files/panolens.min.js"></script>
    <script src="https://js.pusher.com/8.2.0/pusher.min.js"></script>    
    <script type="module" src="/javascript/globalVars.js"></script>
    <script type="module" src="/javascript/loadVenue.js"></script>
    <link rel="stylesheet" href="viewer.css">	
</head>

<body>
    <div id="btn" class="center">
        <img src="assets/talking_head1.gif" class="image">
        <div class ="text">
		        <h2>Start your S P E A K I T eXperience</h2>
		        <p>Turn your phone to the horizontal position, <br> 
               click the Start button and inset it in the VR Set.</p>
	      </div>
        <button class="button" onclick="startWhisper()">Start</button>
    </div>
    
    <div id="container"></div>
    
    <div style="width:100%;margin-top:5%; text-align:center; display:none" id="cheat_not_container">
      <p id="cheat_note" style="word-break: break-all; white-space: normal; display:inline-block; width:20%; margin:5% auto; border-radius:255px 15px 225px 15px/15px 225px 15px 255px; padding:1em; line-height:1.5em; background:hsla(67, 95%, 95%, 1); border:solid 2px hsla(0, 95%, 35%, 1)">
	    Be cool. Everything is allright.
      </p>
    </div>	


    <script>
      // Check browser support for the Web Speech API
      if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
        // Initialize SpeechRecognition object
        var SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        var recognition = new SpeechRecognition();
        
        // Configure recognition settings
        recognition.continuous = true; // Continue listening for speech
        recognition.interimResults = false; // Get interim results before final transcription
        recognition.lang = 'en-US'; // Language setting (adjust as needed)
  
        // Start listening when button is clicked
        //document.getElementById('startButton').addEventListener('click', function() {
        recognition.start();
        
        // Variable to track if "Hi Whisper" has been spoken
        let hiWhisperSpoken = false;
        let welcomeSpoken = false;
  
    
  
        // Event handler for receiving transcribed text
        recognition.onresult = function(event) {
        if (hiWhisperSpoken) {
            var result = event.results[event.results.length - 1];
            var transcript = result[0].transcript;
            var isFinal = result.isFinal;
            if (transcript.toLowerCase().includes('thank you')) { 
              const startPhrase = "hey whisper";
              const stopPhrase = "thank you";
              
              var concatenatedString = concatenateAfterSpecificPhrase(event.results, startPhrase, stopPhrase);
              console.log(concatenatedString); 
              hiWhisperSpoken=false;
              const whisperFinalResponsePath = "assets/ok_give_me_few_seconds.mp3";
              PlaySound(whisperFinalResponsePath);
              hideWhisper();
              //document.getElementById("count_down").style.display = "compact";
              loadWhisperVenue(concatenatedString);
            } else if (transcript.toLowerCase().includes('goodbye')) { 
              PlaySound( "assets/see_you_later.mp3");
              hideWhisper();
            }
        }else {
            const transcript = event.results[event.results.length - 1][0].transcript;
            if (transcript.toLowerCase().includes('hey whisper')) {
                hiWhisperSpoken = true;
                showWhisper();
                var whisperInitResponsePath = "assets/hi.mp3";
                if (!welcomeSpoken){
                  welcomeSpoken = true;
                }else{
                   whisperInitResponsePath = "assets/yes.mp3"
                }
                PlaySound(whisperInitResponsePath);
            } else if (transcript.toLowerCase().includes('any questions')) {
              PlaySound( "assets/questions_please.mp3");
              // call ChatGPT API to generate questions from the prompt
            }
        }
      };
  
        // Event handler for errors
      recognition.onerror = function(event) {
          console.error('Speech recognition error:', event.error);
        };
      } else {
        // Browser doesn't support Web Speech API
        console.error('Browser does not support Web Speech API');
      }

      // Event handler for when speech recognition ends
      recognition.onend = function() {
        console.log('Speech recognition ended');
      // Automatically restart speech recognition after it ends
        recognition.start();
      };

    window.showWhisper = function showWhisper(){
      if(infospot == null){
        infospot = new PANOLENS.Infospot(500, 'assets/talking_head1.gif', true);
        //infospot.addHoverElement(document.getElementById('cheat_note'), 200);
        infospot.position.set(0, -0, -1000); //infospot.dispose();
        panorama.add(infospot);
      }
  
      infospot.show();
    }
  
    window.hideWhisper = function hideWhisper(){
      if(infospot != null){
        infospot.hide();
      }
    }
  
function startWhisper() {
      container = document.querySelector('#container');
      noSleep.enable();
      document.getElementById("btn").style.display = "none";
      //document.getElementById("count_down").style.display = "none";
      //var audio = new Audio('assets/imagine_l1.mp3');
      //audio.loop = true;
      //audio.play();
    
  
      panorama = new PANOLENS.ImagePanorama('assets/imagine1.jpeg', 50);
    
      panorama.addEventListener('enter-fade-start', () => {
          viewer.tweenControlCenter(new THREE.Vector3(0,0,0), 0)
      })
      viewer = new PANOLENS.Viewer({ container: container });
      viewer.add(panorama);
    
      var ef = 1, ctrl = 0;
      if (/Mobile|Android|iP(hone|od)|IEMobile|BlackBerry|Kindle|Silk-Accelerated|(hpw|web)OS|Opera M(obi|ini)/.test(navigator.userAgent)) {
          ef = 2;
          ctrl = 1;
      }
      viewer.enableControl(ctrl);
      viewer.enableEffect(ef);
      viewer.setCameraFov(90);
      
}

function PlaySound(audioPath) {
    var audio = new Audio(audioPath);
    audio.loop = false;
    audio.play();
}

function speak(textToSay) {
      // Check browser support for SpeechSynthesis
      if ('speechSynthesis' in window) {
        // Create a new instance of SpeechSynthesisUtterance
        var utterance = new SpeechSynthesisUtterance(textToSay);

        // Optionally, configure speech parameters
        utterance.lang = 'en-US'; // Language setting (adjust as needed)

        // Speak the text
        window.speechSynthesis.speak(utterance);
      } else {
        // Browser doesn't support SpeechSynthesis
        alert('Your browser does not support text-to-speech.');
      }
    }

function concatenateAfterSpecificPhrase(array, startKeyword, endKeyword) {
    let isConcatenating = false;
    let result = '';
    var currentPhrase="";

    for (let i = 0; i < array.length; i++) {
         currentPhrase += array[i][0].transcript;
    }
    const startRegex = new RegExp(startKeyword + '(.*?)' + endKeyword, 'g');
        
  // Find all matches
    let match;
    while ((match = startRegex.exec(currentPhrase.toLowerCase())) !== null) {
        result += match[1]; // Concatenate the text between the keywords
    }

    return result;
    
}

//Generates the request to the Blockadel API to generate 360 inage from the prompt
//the function generte asynchronous request. The response will be received by webhook function loadVenueEvent()
async function loadWhisperVenue(imagePrompt) {
    
    speak(imagePrompt); 

    noSleep.enable();
  
    document.getElementById("btn").style.display = "none";

    container = document.querySelector('#container');
              
    let requestOptions = {
        method: "POST",
        headers: myHeaders,
        redirect: "follow"
    };

    //const response = await fetch(`https://backend.blockadelabs.com/api/v1/skybox?prompt=${imagePrompt}`, requestOptions);
    //const data = await response.json();

    Pusher.logToConsole = true;
    pusher = new Pusher('a6a7b7662238ce4494d5', {
    appId: "1555452",
    key: "a6a7b7662238ce4494d5",
    secret: "5b69dc3f0bb7800ed8d0",
    cluster: "mt1"
    });
    
    //channel = pusher.subscribe(data.pusher_channel);
   // channel.bind(data.pusher_event, loadVenueEvent);      
}    
    </script>
</body>
</html>